{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, NearMiss\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "credit_data = pd.read_csv('Creditcard_data.csv')\n",
        "class_distribution = credit_data['Class'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Majority class (0): (763, 31)\n",
            "Minority class (1): (9, 31)\n"
          ]
        }
      ],
      "source": [
        "# Separate majority and minority classes\n",
        "majority_class = credit_data[credit_data['Class'] == 0]\n",
        "minority_class = credit_data[credit_data['Class'] == 1]\n",
        "print(f'Majority class (0): {majority_class.shape}')\n",
        "print(f'Minority class (1): {minority_class.shape}')\n",
        "\n",
        "# Split features and target\n",
        "features = credit_data.drop(columns='Class')\n",
        "target = credit_data['Class']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define resampling methods\n",
        "# Modified Sampling Techniques\n",
        "def apply_smote(X, y):\n",
        "    smote = SMOTE(random_state=30, k_neighbors=5)  # Adjusted SMOTE parameters\n",
        "    return smote.fit_resample(X, y)\n",
        "\n",
        "def apply_random_undersampling(X, y):\n",
        "    undersampler = RandomUnderSampler(random_state=50, replacement=False)  # Changed replacement to False\n",
        "    return undersampler.fit_resample(X, y)\n",
        "\n",
        "def apply_random_oversampling(X, y):\n",
        "    oversampler = RandomOverSampler(random_state=60, sampling_strategy=0.8)  # Adjusted sampling strategy\n",
        "    return oversampler.fit_resample(X, y)\n",
        "\n",
        "def apply_tomek_links(X, y):\n",
        "    tomek = TomekLinks()\n",
        "    return tomek.fit_resample(X, y)\n",
        "\n",
        "def apply_nearmiss(X, y):\n",
        "    nearmiss = NearMiss()\n",
        "    return nearmiss.fit_resample(X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Updated Train-Test Split Ratio and Random States\n",
        "def evaluate_logistic_regression(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)\n",
        "    classifier = LogisticRegression(max_iter=200)  # Increased max iterations\n",
        "    classifier.fit(X_train, y_train)\n",
        "    predictions = classifier.predict(X_test)\n",
        "    return accuracy_score(y_test, predictions)\n",
        "\n",
        "def evaluate_decision_tree(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=20)\n",
        "    classifier = DecisionTreeClassifier(max_depth=5, random_state=10)  # Limited tree depth\n",
        "    classifier.fit(X_train, y_train)\n",
        "    predictions = classifier.predict(X_test)\n",
        "    return accuracy_score(y_test, predictions)\n",
        "\n",
        "def evaluate_random_forest(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30)\n",
        "    classifier = RandomForestClassifier(n_estimators=50, random_state=15)  # Reduced estimators\n",
        "    classifier.fit(X_train, y_train)\n",
        "    predictions = classifier.predict(X_test)\n",
        "    return accuracy_score(y_test, predictions)\n",
        "\n",
        "def evaluate_svm(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=40)\n",
        "    classifier = SVC(kernel='poly', degree=3, random_state=20)  # Changed kernel to polynomial\n",
        "    classifier.fit(X_train, y_train)\n",
        "    predictions = classifier.predict(X_test)\n",
        "    return accuracy_score(y_test, predictions)\n",
        "\n",
        "def evaluate_knn(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=50)\n",
        "    classifier = KNeighborsClassifier(n_neighbors=5, metric='manhattan')  # Changed distance metric\n",
        "    classifier.fit(X_train, y_train)\n",
        "    predictions = classifier.predict(X_test)\n",
        "    return accuracy_score(y_test, predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Vaibhav Tandon\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\Vaibhav Tandon\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\Vaibhav Tandon\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\Vaibhav Tandon\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        LogReg  DecisionTree  RandomForest       SVM       KNN\n",
            "Random Undersampling  0.600000      0.800000      0.200000  0.600000  0.400000\n",
            "Random Oversampling   0.904070      0.968023      1.000000  0.688953  0.982558\n",
            "Tomek Links           0.984375      0.963542      0.979167  1.000000  0.994792\n",
            "SMOTE                 0.895288      0.950262      1.000000  0.696335  0.848168\n",
            "NearMiss              0.400000      0.600000      0.200000  0.600000  0.400000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Vaibhav Tandon\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# Generate results matrix\n",
        "sampling_methods = [\n",
        "    apply_random_undersampling,\n",
        "    apply_random_oversampling,\n",
        "    apply_tomek_links,\n",
        "    apply_smote,\n",
        "    apply_nearmiss,\n",
        "]\n",
        "\n",
        "classifiers = [\n",
        "    evaluate_logistic_regression,\n",
        "    evaluate_decision_tree,\n",
        "    evaluate_random_forest,\n",
        "    evaluate_svm,\n",
        "    evaluate_knn,\n",
        "]\n",
        "\n",
        "results = []\n",
        "row_labels = [\"Random Undersampling\", \"Random Oversampling\", \"Tomek Links\", \"SMOTE\", \"NearMiss\"]\n",
        "column_labels = [\"LogReg\", \"DecisionTree\", \"RandomForest\", \"SVM\", \"KNN\"]\n",
        "\n",
        "for resampling in sampling_methods:\n",
        "    row_results = []\n",
        "    for classifier in classifiers:\n",
        "        X_resampled, y_resampled = resampling(features, target)\n",
        "        accuracy = classifier(X_resampled, y_resampled)\n",
        "        row_results.append(accuracy)\n",
        "    results.append(row_results)\n",
        "\n",
        "# Create updated DataFrame\n",
        "updated_performance_df = pd.DataFrame(results, columns=column_labels, index=row_labels)\n",
        "print(updated_performance_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
